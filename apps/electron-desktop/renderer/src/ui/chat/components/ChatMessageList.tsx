import React from "react";
import Markdown, { type Components } from "react-markdown";
import remarkGfm from "remark-gfm";
import remarkMath from "remark-math";
import rehypeKatex from "rehype-katex";

import type {
  UiMessageAttachment,
  UiToolCall,
  UiToolResult,
  LiveToolCall,
} from "@store/slices/chatSlice";
import { isHeartbeatMessage } from "@store/slices/chatSlice";
import type { ChatAttachmentInput } from "@store/slices/chatSlice";
import { CopyMessageButton } from "./CopyMessageButton";
import { UserMessageBubble } from "./UserMessageBubble";
import { AssistantStreamBubble, TypingIndicator } from "./AssistantStreamBubble";
import { HIDDEN_TOOL_NAMES } from "./ToolCallCard";
import { ActionLog } from "./ActionLog";
import { AudioPlayer } from "./AudioPlayer";
import { extractAudioFiles, isNoReplyMessage } from "../hooks/messageParser";
import am from "./AssistantMessage.module.css";
import ct from "../ChatTranscript.module.css";

type DisplayMessage = {
  id: string;
  role: "user" | "assistant";
  text: string;
  pending?: boolean;
  attachments?: UiMessageAttachment[];
  toolCalls?: UiToolCall[];
  toolResults?: UiToolResult[];
};

type StreamEntry = {
  id: string;
  role: string;
  text: string;
};

export function ChatMessageList(props: {
  displayMessages: DisplayMessage[];
  streamByRun: Record<string, StreamEntry>;
  liveToolCalls: LiveToolCall[];
  optimisticFirstMessage: string | null;
  optimisticFirstAttachments: ChatAttachmentInput[] | null;
  matchingFirstUserFromHistory: DisplayMessage | null;
  waitingForFirstResponse: boolean;
  markdownComponents: Components;
  scrollRef: React.RefObject<HTMLDivElement | null>;
}) {
  const {
    displayMessages,
    streamByRun,
    liveToolCalls,
    optimisticFirstMessage,
    optimisticFirstAttachments,
    matchingFirstUserFromHistory,
    waitingForFirstResponse,
    markdownComponents,
    scrollRef,
  } = props;

  /** Stable key for the first user message so React doesn't remount when switching from optimistic to history. */
  const getMessageKey = (m: DisplayMessage) =>
    (optimisticFirstMessage != null && m.id === "opt-first") ||
    (matchingFirstUserFromHistory != null && m.id === matchingFirstUserFromHistory.id)
      ? "first-user"
      : m.id;

  // Group consecutive tool-call-only assistant messages into single blocks.
  type RenderItem =
    | { kind: "user"; msg: DisplayMessage }
    | { kind: "assistant"; msg: DisplayMessage }
    | { kind: "tool-group"; msgs: DisplayMessage[] };

  const renderItems: RenderItem[] = [];
  for (const m of displayMessages) {
    if (m.role === "user") {
      renderItems.push({ kind: "user", msg: m });
      continue;
    }
    const isToolOnly = !m.text && m.toolCalls && m.toolCalls.length > 0;
    if (isToolOnly) {
      const prev = renderItems[renderItems.length - 1];
      if (prev?.kind === "tool-group") {
        prev.msgs.push(m);
      } else {
        renderItems.push({ kind: "tool-group", msgs: [m] });
      }
    } else {
      renderItems.push({ kind: "assistant", msg: m });
    }
  }

  const streamBubbles = Object.values(streamByRun).filter(
    (m) => !isHeartbeatMessage(m.role, m.text) && !isNoReplyMessage(m.text)
  );
  const hasStreamBubbles = streamBubbles.length > 0;
  const lastAssistantRenderIndex =
    renderItems.length > 0
      ? [...renderItems]
          .reverse()
          .findIndex((i) => i.kind === "assistant" || i.kind === "tool-group")
      : -1;
  const lastAssistantFromRenderItems =
    lastAssistantRenderIndex >= 0 ? renderItems.length - 1 - lastAssistantRenderIndex : -1;

  return (
    <div className={ct.UiChatTranscript + " scrollable"} ref={scrollRef}>
      <div className={ct.UiChatTranscriptInner}>
        {renderItems.map((item, index) => {
          if (item.kind === "user") {
            const m = item.msg;
            const attachmentsToShow: UiMessageAttachment[] =
              m.id === "opt-first" && optimisticFirstAttachments?.length
                ? optimisticFirstAttachments.map((att) => ({
                    type: att.mimeType?.startsWith("image/") ? "image" : "file",
                    mimeType: att.mimeType,
                    dataUrl: att.dataUrl,
                  }))
                : (m.attachments ?? []);
            return (
              <UserMessageBubble
                key={getMessageKey(m)}
                id={m.id}
                text={m.text}
                pending={m.pending}
                attachments={attachmentsToShow}
                markdownComponents={markdownComponents}
              />
            );
          }

          if (item.kind === "tool-group") {
            const key = item.msgs.map((m) => getMessageKey(m)).join("+");
            const isLastAssistant =
              !hasStreamBubbles &&
              liveToolCalls.length === 0 &&
              !waitingForFirstResponse &&
              index === lastAssistantFromRenderItems;
            const resultMap = new Map<string, UiToolResult>();
            for (const m of item.msgs) {
              for (const r of m.toolResults ?? []) {
                if (r.toolCallId) resultMap.set(r.toolCallId, r);
              }
            }
            const flatCards: { toolCall: UiToolCall; result?: UiToolResult }[] = [];
            for (const m of item.msgs) {
              const list = (m.toolCalls ?? []).filter((tc) => !HIDDEN_TOOL_NAMES.has(tc.name));
              for (const tc of list) {
                flatCards.push({ toolCall: tc, result: resultMap.get(tc.id) });
              }
            }

            // Extract audio from tool results in tool-group messages.
            const toolGroupAudio: string[] = [];
            for (const m of item.msgs) {
              for (const r of m.toolResults ?? []) {
                if (r.text) {
                  for (const src of extractAudioFiles(r.text)) {
                    toolGroupAudio.push(src);
                  }
                }
              }
            }

            return (
              <div
                key={key}
                className={`${ct.UiChatRow} ${ct.UiChatRowToolGroup} ${am["UiChatRow-assistant"]} ${isLastAssistant ? ct.UiChatRowLastAssistant : ""}`}
              >
                <div className={am["UiChatBubble-assistant"]}>
                  <ActionLog cards={flatCards} />
                  {toolGroupAudio.map((src, i) => (
                    <AudioPlayer key={`tg-audio-${i}`} src={src} />
                  ))}
                </div>
              </div>
            );
          }

          // Assistant message with text (may also have tool calls)
          const m = item.msg;
          const isLastAssistant =
            !hasStreamBubbles &&
            liveToolCalls.length === 0 &&
            !waitingForFirstResponse &&
            index === lastAssistantFromRenderItems;

          const flatCards: { toolCall: UiToolCall; result?: UiToolResult }[] =
            m.toolCalls?.map((toolCall, index) => ({
              toolCall,
              result: m.toolResults?.[index],
            })) ?? [];

          // Extract audio files from tool results (e.g. TTS tool output).
          const audioSrcs: string[] = [];
          for (const r of m.toolResults ?? []) {
            if (r.text) {
              for (const src of extractAudioFiles(r.text)) {
                audioSrcs.push(src);
              }
            }
          }
          // Also check message text itself for inline MEDIA: audio references.
          if (m.text) {
            for (const src of extractAudioFiles(m.text)) {
              audioSrcs.push(src);
            }
          }

          const hasAudio = audioSrcs.length > 0;
          const showText = m.text && !isNoReplyMessage(m.text);

          return (
            <div
              key={getMessageKey(m)}
              className={`${ct.UiChatRow} ${am["UiChatRow-assistant"]} ${isLastAssistant ? ct.UiChatRowLastAssistant : ""}`}
            >
              <div className={am["UiChatBubble-assistant"]}>
                {flatCards.length > 0 ? <ActionLog cards={flatCards} /> : null}

                {hasAudio
                  ? audioSrcs.map((src, i) => <AudioPlayer key={`audio-${i}`} src={src} />)
                  : null}

                {showText ? (
                  <div className="UiChatText UiMarkdown">
                    <Markdown
                      remarkPlugins={[remarkGfm, remarkMath]}
                      rehypePlugins={[rehypeKatex]}
                      components={markdownComponents}
                    >
                      {m.text}
                    </Markdown>
                  </div>
                ) : null}

                {showText ? (
                  <div className={am.UiChatMessageActions}>
                    <CopyMessageButton text={m.text} />
                  </div>
                ) : null}
              </div>
            </div>
          );
        })}
        {waitingForFirstResponse ? (
          <TypingIndicator
            classNameRoot={
              !hasStreamBubbles && liveToolCalls.length === 0
                ? ct.UiChatRowLastAssistant
                : undefined
            }
          />
        ) : null}

        {liveToolCalls.length > 0 ? (
          <div
            className={`${ct.UiChatRow} ${am["UiChatRow-assistant"]} ${!hasStreamBubbles ? ct.UiChatRowLastAssistant : ""}`}
          >
            <div className={am["UiChatBubble-assistant"]}>
              <ActionLog liveToolCalls={liveToolCalls} />
            </div>
          </div>
        ) : null}

        {streamBubbles.map((m, i) => (
          <AssistantStreamBubble
            key={m.id}
            id={m.id}
            text={m.text}
            markdownComponents={markdownComponents}
            classNameRoot={i === streamBubbles.length - 1 ? ct.UiChatRowLastAssistant : undefined}
          />
        ))}
      </div>
    </div>
  );
}
